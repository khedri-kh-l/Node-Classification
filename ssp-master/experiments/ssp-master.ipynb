{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20d2c022",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "\n",
    "from datasets import get_planetoid_dataset\n",
    "from train_eval import run, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72ce78cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--dataset', type=str, default=\"cora\")\n",
    "parser.add_argument('--split', type=str, default='public')\n",
    "parser.add_argument('--runs', type=int, default=10)\n",
    "parser.add_argument('--epochs', type=int, default=200)\n",
    "parser.add_argument('--lr', type=float, default=0.01)\n",
    "parser.add_argument('--weight_decay', type=float, default=0.0005)\n",
    "parser.add_argument('--early_stopping', type=int, default=0)\n",
    "parser.add_argument('--hidden', type=int, default=16)\n",
    "parser.add_argument('--dropout', type=float, default=0.5)\n",
    "parser.add_argument('--normalize_features', type=bool, default=True)\n",
    "parser.add_argument('--logger', type=str, default=None)\n",
    "parser.add_argument('--optimizer', type=str, default='Adam')\n",
    "parser.add_argument('--preconditioner', type=str, default=None)\n",
    "parser.add_argument('--momentum', type=float, default=0.9)\n",
    "parser.add_argument('--eps', type=float, default=0.01)\n",
    "parser.add_argument('--update_freq', type=int, default=50)\n",
    "parser.add_argument('--gamma', type=float, default=None)\n",
    "parser.add_argument('--alpha', type=float, default=None)\n",
    "parser.add_argument('--hyperparam', type=str, default=None)\n",
    "args, unknown = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "306269ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_planetoid_dataset(name=args.dataset, normalize_features=args.normalize_features, split=args.split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89d0f8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_orig(torch.nn.Module):\n",
    "    def __init__(self, dataset):\n",
    "        super(Net2, self).__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_features, args.hidden)\n",
    "        self.conv2 = GCNConv(args.hidden, dataset.num_classes)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.conv1.reset_parameters()\n",
    "        self.conv2.reset_parameters()\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, p=args.dropout, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "class CRD(torch.nn.Module):\n",
    "    def __init__(self, d_in, d_out, p):\n",
    "        super(CRD, self).__init__()\n",
    "        self.conv = GCNConv(d_in, d_out, cached=True) \n",
    "        self.p = p\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.conv.reset_parameters()\n",
    "\n",
    "    def forward(self, x, edge_index, mask=None):\n",
    "        x = F.relu(self.conv(x, edge_index))\n",
    "        x = F.dropout(x, p=self.p, training=self.training)\n",
    "        return x\n",
    "\n",
    "class CLS(torch.nn.Module):\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super(CLS, self).__init__()\n",
    "        self.conv = GCNConv(d_in, d_out, cached=True)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.conv.reset_parameters()\n",
    "\n",
    "    def forward(self, x, edge_index, mask=None):\n",
    "        x = self.conv(x, edge_index)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "    \n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, dataset):\n",
    "        super(Net, self).__init__()\n",
    "        self.crd = CRD(dataset.num_features, args.hidden, args.dropout)\n",
    "        self.cls = CLS(args.hidden, dataset.num_classes)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.crd.reset_parameters()\n",
    "        self.cls.reset_parameters()\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.crd(x, edge_index, data.train_mask)\n",
    "        x = self.cls(x, edge_index, data.train_mask)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79a6006b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    'dataset': dataset, \n",
    "    'model': Net(dataset), \n",
    "    'str_optimizer': args.optimizer, \n",
    "    'str_preconditioner': args.preconditioner, \n",
    "    'runs': args.runs, \n",
    "    'epochs': args.epochs, \n",
    "    'lr': args.lr, \n",
    "    'weight_decay': args.weight_decay, \n",
    "    'early_stopping': args.early_stopping, \n",
    "    'logger': args.logger, \n",
    "    'momentum': args.momentum,\n",
    "    'eps': args.eps,\n",
    "    'update_freq': args.update_freq,\n",
    "    'gamma': args.gamma,\n",
    "    'alpha': args.alpha,\n",
    "    'hyperparam': args.hyperparam\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48e74ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.8192, Test Accuracy: 80.87 Â± 0.84, Duration: 8.379 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "if args.hyperparam == 'eps':\n",
    "    for param in np.logspace(-3, 0, 10, endpoint=True):\n",
    "        print(f\"{args.hyperparam}: {param}\")\n",
    "        kwargs[args.hyperparam] = param\n",
    "        run(**kwargs)\n",
    "elif args.hyperparam == 'update_freq':\n",
    "    for param in [4, 8, 16, 32, 64, 128]:\n",
    "        print(f\"{args.hyperparam}: {param}\")\n",
    "        kwargs[args.hyperparam] = param\n",
    "        run(**kwargs)\n",
    "elif args.hyperparam == 'gamma':\n",
    "    for param in np.linspace(1., 10., 10, endpoint=True):\n",
    "        print(f\"{args.hyperparam}: {param}\")\n",
    "        kwargs[args.hyperparam] = param\n",
    "        run(**kwargs)\n",
    "else:\n",
    "    run(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34eaadce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6358ccf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train loss': 1.9452314376831055,\n",
       " 'train acc': 0.15714285714285714,\n",
       " 'val loss': 1.9449515342712402,\n",
       " 'val acc': 0.252,\n",
       " 'test loss': 1.9448139667510986,\n",
       " 'test acc': 0.261}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(Net(dataset), dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51943571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time inference:0.1298234462738037  \n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "evaluate(Net(dataset), dataset[0])\n",
    "end = time.time()\n",
    "t_inference= end-start\n",
    "print(f\"Time inference:{t_inference}  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ecae876",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_parameters(model, count_nonzero_only=False) -> int:\n",
    "    \"\"\"\n",
    "    calculate the total number of parameters of model\n",
    "    :param count_nonzero_only: only count nonzero weights\n",
    "    \"\"\"\n",
    "    num_counted_elements = 0\n",
    "    for param in model.parameters():\n",
    "        if count_nonzero_only:\n",
    "            num_counted_elements += param.count_nonzero()\n",
    "        else:\n",
    "            num_counted_elements += param.numel()\n",
    "    return num_counted_elements\n",
    "\n",
    "\n",
    "def get_model_size(model, data_width=32, count_nonzero_only=False) -> int:\n",
    "    \"\"\"\n",
    "    calculate the model size in bits\n",
    "    :param data_width: #bits per element\n",
    "    :param count_nonzero_only: only count nonzero weights\n",
    "    \"\"\"\n",
    "    return get_num_parameters(model, count_nonzero_only) * data_width\n",
    "\n",
    "Byte = 8\n",
    "KiB = 1024 * Byte\n",
    "MiB = 1024 * KiB\n",
    "GiB = 1024 * MiB\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42e6d956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "738016"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_model_size(Net(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6fda65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e4222a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
