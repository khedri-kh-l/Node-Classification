{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2bb697a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from datetime import datetime\n",
    "\n",
    "import itertools\n",
    "import os\n",
    "#from utils import *\n",
    "\n",
    "\n",
    "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
    "\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse as sp\n",
    "import torch.nn.utils.prune as prune\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5feec43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"../\"))\n",
    "\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f5e686f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e6d79d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_parameters(model: nn.Module, count_nonzero_only=False) -> int:\n",
    "    \"\"\"\n",
    "    calculate the total number of parameters of model\n",
    "    :param count_nonzero_only: only count nonzero weights\n",
    "    \"\"\"\n",
    "    num_counted_elements = 0\n",
    "    for param in model.parameters():\n",
    "        if count_nonzero_only:\n",
    "            num_counted_elements += param.count_nonzero()\n",
    "        else:\n",
    "            num_counted_elements += param.numel()\n",
    "    return num_counted_elements\n",
    "\n",
    "\n",
    "def get_model_size(model: nn.Module, data_width=32, count_nonzero_only=False) -> int:\n",
    "    \"\"\"\n",
    "    calculate the model size in bits\n",
    "    :param data_width: #bits per element\n",
    "    :param count_nonzero_only: only count nonzero weights\n",
    "    \"\"\"\n",
    "    return get_num_parameters(model, count_nonzero_only) * data_width\n",
    "\n",
    "Byte = 8\n",
    "KiB = 1024 * Byte\n",
    "MiB = 1024 * KiB\n",
    "GiB = 1024 * MiB\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c734c7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, 16)\n",
    "        self.conv2 = GCNConv(16, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    \n",
    "model = GCN(dataset.num_features, dataset.num_classes)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1712f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "   \n",
    "        \n",
    "    logits, accs = model(dataset[0]), []\n",
    "    for _, mask in dataset[0]('train_mask', 'val_mask', 'test_mask'):\n",
    "        pred = logits[mask].max(1)[1]\n",
    "        acc = pred.eq(dataset[0].y[mask]).sum().item() / mask.sum().item()\n",
    "        accs.append(acc)\n",
    "    return accs  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7cd83fc4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m      7\u001b[0m logits\u001b[38;5;241m=\u001b[39m model(dataset[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m----> 8\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mlogits\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      9\u001b[0m val_acc \u001b[38;5;241m=\u001b[39m pred\u001b[38;5;241m.\u001b[39meq(dataset[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39my[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_mask\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m/\u001b[39mdataset[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39my[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     10\u001b[0m test_acc \u001b[38;5;241m=\u001b[39m pred\u001b[38;5;241m.\u001b[39meq(dataset[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39my[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_mask\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m/\u001b[39mdataset[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39my[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch_geometric\\data\\data.py:457\u001b[0m, in \u001b[0;36mData.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m--> 457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_store\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch_geometric\\data\\storage.py:104\u001b[0m, in \u001b[0;36mBaseStorage.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m--> 104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 100):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    F.nll_loss(model(dataset[0]), dataset[0].y).backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    logits= model(dataset[0])\n",
    "    pred = logits[mask].max(1)[1]\n",
    "    val_acc = pred.eq(dataset[0].y['val_mask']).sum().item() /dataset[0].y['val_mask'].sum().item()\n",
    "    test_acc = pred.eq(dataset[0].y['test_mask']).sum().item() /dataset[0].y['test_mask'].sum().item()\n",
    "    \n",
    "   \n",
    "    if epoch % 20 == 0:\n",
    "        print(f'Epoch: {epoch:03d},  Val: {val_acc:.4f}, Test: {test_acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "342f5f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 020, Train: 0.8357, Val: 0.8300, Test: 0.8520\n",
      "Epoch: 040, Train: 0.8857, Val: 0.9000, Test: 0.8990\n",
      "Epoch: 060, Train: 0.9357, Val: 0.9200, Test: 0.9210\n",
      "Epoch: 080, Train: 0.9643, Val: 0.9220, Test: 0.9180\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 100):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    F.nll_loss(model(dataset[0]), dataset[0].y).backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    train_acc, val_acc, test_acc = test()\n",
    "    if epoch % 20 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Train: {train_acc:.4f}, Val: {val_acc:.4f}, Test: {test_acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b07f35a3",
   "metadata": {},
   "outputs": [],
   "source": [
    " train_acc, val_acc, test_acc = test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc5297b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9571428571428572 0.938 0.926\n"
     ]
    }
   ],
   "source": [
    "print( train_acc, val_acc, test_acc )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa6aef5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75f30c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd6acb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "http://localhost:8888/notebooks/GNN/Node-Classification/GCN-Torch-Geo/Node_Classificaton_GCN_Geometric.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "010185b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import SplineConv\n",
    "from torch_geometric.typing import WITH_TORCH_SPLINE_CONV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1aecaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not WITH_TORCH_SPLINE_CONV:\n",
    "    quit(\"This example requires 'torch-spline-conv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a2b7c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset = 'Cora'\n",
    "transform = T.Compose([\n",
    "    T.RandomNodeSplit(num_val=500, num_test=500),\n",
    "    T.TargetIndegree(),\n",
    "])\n",
    "path = osp.join( 'data', dataset)\n",
    "dataset = Planetoid(path, dataset, transform=transform)\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9ccfab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = SplineConv(dataset.num_features, 16, dim=1, kernel_size=2)\n",
    "        self.conv2 = SplineConv(16, dataset.num_classes, dim=1, kernel_size=2)\n",
    "\n",
    "    def forward(self):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.elu(self.conv1(x, edge_index, edge_attr))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba0d184d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model, data = Net().to(device), data.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17680db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train: 0.6382, Test: 0.6080\n",
      "Epoch: 002, Train: 0.6347, Test: 0.5960\n",
      "Epoch: 003, Train: 0.6446, Test: 0.5880\n",
      "Epoch: 004, Train: 0.6926, Test: 0.6300\n",
      "Epoch: 005, Train: 0.7664, Test: 0.7080\n",
      "Epoch: 006, Train: 0.8513, Test: 0.7880\n",
      "Epoch: 007, Train: 0.8975, Test: 0.8320\n",
      "Epoch: 008, Train: 0.9081, Test: 0.8400\n",
      "Epoch: 009, Train: 0.9133, Test: 0.8520\n",
      "Epoch: 010, Train: 0.9145, Test: 0.8560\n",
      "Epoch: 011, Train: 0.9174, Test: 0.8660\n",
      "Epoch: 012, Train: 0.9215, Test: 0.8720\n",
      "Epoch: 013, Train: 0.9274, Test: 0.8820\n",
      "Epoch: 014, Train: 0.9297, Test: 0.8900\n",
      "Epoch: 015, Train: 0.9315, Test: 0.8900\n",
      "Epoch: 016, Train: 0.9350, Test: 0.8900\n",
      "Epoch: 017, Train: 0.9391, Test: 0.8920\n",
      "Epoch: 018, Train: 0.9479, Test: 0.8880\n",
      "Epoch: 019, Train: 0.9502, Test: 0.8880\n",
      "Epoch: 020, Train: 0.9532, Test: 0.8980\n",
      "Epoch: 021, Train: 0.9567, Test: 0.9000\n",
      "Epoch: 022, Train: 0.9608, Test: 0.9020\n",
      "Epoch: 023, Train: 0.9637, Test: 0.9040\n",
      "Epoch: 024, Train: 0.9637, Test: 0.9120\n",
      "Epoch: 025, Train: 0.9649, Test: 0.9140\n",
      "Epoch: 026, Train: 0.9696, Test: 0.9120\n",
      "Epoch: 027, Train: 0.9701, Test: 0.9080\n",
      "Epoch: 028, Train: 0.9713, Test: 0.9080\n",
      "Epoch: 029, Train: 0.9731, Test: 0.9040\n",
      "Epoch: 030, Train: 0.9713, Test: 0.9080\n",
      "Epoch: 031, Train: 0.9719, Test: 0.9080\n",
      "Epoch: 032, Train: 0.9731, Test: 0.9080\n",
      "Epoch: 033, Train: 0.9725, Test: 0.9060\n",
      "Epoch: 034, Train: 0.9719, Test: 0.9020\n",
      "Epoch: 035, Train: 0.9731, Test: 0.9060\n",
      "Epoch: 036, Train: 0.9719, Test: 0.9000\n",
      "Epoch: 037, Train: 0.9731, Test: 0.8980\n",
      "Epoch: 038, Train: 0.9725, Test: 0.8940\n",
      "Epoch: 039, Train: 0.9742, Test: 0.8960\n",
      "Epoch: 040, Train: 0.9783, Test: 0.8980\n",
      "Epoch: 041, Train: 0.9766, Test: 0.9000\n",
      "Epoch: 042, Train: 0.9742, Test: 0.9020\n",
      "Epoch: 043, Train: 0.9725, Test: 0.9000\n",
      "Epoch: 044, Train: 0.9719, Test: 0.9000\n",
      "Epoch: 045, Train: 0.9731, Test: 0.9000\n",
      "Epoch: 046, Train: 0.9748, Test: 0.8960\n",
      "Epoch: 047, Train: 0.9766, Test: 0.8940\n",
      "Epoch: 048, Train: 0.9766, Test: 0.8960\n",
      "Epoch: 049, Train: 0.9748, Test: 0.8960\n",
      "Epoch: 050, Train: 0.9789, Test: 0.8960\n",
      "Epoch: 051, Train: 0.9772, Test: 0.8940\n",
      "Epoch: 052, Train: 0.9772, Test: 0.8960\n",
      "Epoch: 053, Train: 0.9789, Test: 0.8980\n",
      "Epoch: 054, Train: 0.9789, Test: 0.9040\n",
      "Epoch: 055, Train: 0.9795, Test: 0.9020\n",
      "Epoch: 056, Train: 0.9813, Test: 0.9040\n",
      "Epoch: 057, Train: 0.9807, Test: 0.9060\n",
      "Epoch: 058, Train: 0.9824, Test: 0.9040\n",
      "Epoch: 059, Train: 0.9848, Test: 0.9020\n",
      "Epoch: 060, Train: 0.9836, Test: 0.8980\n",
      "Epoch: 061, Train: 0.9824, Test: 0.9020\n",
      "Epoch: 062, Train: 0.9813, Test: 0.9020\n",
      "Epoch: 063, Train: 0.9819, Test: 0.9000\n",
      "Epoch: 064, Train: 0.9830, Test: 0.9000\n",
      "Epoch: 065, Train: 0.9824, Test: 0.9000\n",
      "Epoch: 066, Train: 0.9801, Test: 0.9000\n",
      "Epoch: 067, Train: 0.9795, Test: 0.8980\n",
      "Epoch: 068, Train: 0.9795, Test: 0.8980\n",
      "Epoch: 069, Train: 0.9778, Test: 0.9000\n",
      "Epoch: 070, Train: 0.9760, Test: 0.9000\n",
      "Epoch: 071, Train: 0.9754, Test: 0.9020\n",
      "Epoch: 072, Train: 0.9783, Test: 0.9000\n",
      "Epoch: 073, Train: 0.9772, Test: 0.8980\n",
      "Epoch: 074, Train: 0.9789, Test: 0.9020\n",
      "Epoch: 075, Train: 0.9778, Test: 0.8980\n",
      "Epoch: 076, Train: 0.9778, Test: 0.8980\n",
      "Epoch: 077, Train: 0.9778, Test: 0.9000\n",
      "Epoch: 078, Train: 0.9772, Test: 0.8980\n",
      "Epoch: 079, Train: 0.9778, Test: 0.9000\n",
      "Epoch: 080, Train: 0.9789, Test: 0.8960\n",
      "Epoch: 081, Train: 0.9795, Test: 0.8980\n",
      "Epoch: 082, Train: 0.9801, Test: 0.9000\n",
      "Epoch: 083, Train: 0.9807, Test: 0.8920\n",
      "Epoch: 084, Train: 0.9807, Test: 0.8960\n",
      "Epoch: 085, Train: 0.9795, Test: 0.8960\n",
      "Epoch: 086, Train: 0.9819, Test: 0.8920\n",
      "Epoch: 087, Train: 0.9854, Test: 0.8980\n",
      "Epoch: 088, Train: 0.9865, Test: 0.9020\n",
      "Epoch: 089, Train: 0.9830, Test: 0.9040\n",
      "Epoch: 090, Train: 0.9854, Test: 0.9020\n",
      "Epoch: 091, Train: 0.9830, Test: 0.8980\n",
      "Epoch: 092, Train: 0.9819, Test: 0.8960\n",
      "Epoch: 093, Train: 0.9778, Test: 0.8980\n",
      "Epoch: 094, Train: 0.9824, Test: 0.8980\n",
      "Epoch: 095, Train: 0.9842, Test: 0.9060\n",
      "Epoch: 096, Train: 0.9854, Test: 0.9060\n",
      "Epoch: 097, Train: 0.9836, Test: 0.9080\n",
      "Epoch: 098, Train: 0.9819, Test: 0.9060\n",
      "Epoch: 099, Train: 0.9830, Test: 0.9060\n",
      "Epoch: 100, Train: 0.9824, Test: 0.9020\n",
      "Epoch: 101, Train: 0.9807, Test: 0.9040\n",
      "Epoch: 102, Train: 0.9813, Test: 0.9120\n",
      "Epoch: 103, Train: 0.9819, Test: 0.9140\n",
      "Epoch: 104, Train: 0.9830, Test: 0.9100\n",
      "Epoch: 105, Train: 0.9836, Test: 0.9040\n",
      "Epoch: 106, Train: 0.9842, Test: 0.9040\n",
      "Epoch: 107, Train: 0.9848, Test: 0.9040\n",
      "Epoch: 108, Train: 0.9865, Test: 0.9020\n",
      "Epoch: 109, Train: 0.9865, Test: 0.9040\n",
      "Epoch: 110, Train: 0.9865, Test: 0.9060\n",
      "Epoch: 111, Train: 0.9859, Test: 0.9060\n",
      "Epoch: 112, Train: 0.9859, Test: 0.9060\n",
      "Epoch: 113, Train: 0.9877, Test: 0.9020\n",
      "Epoch: 114, Train: 0.9842, Test: 0.9000\n",
      "Epoch: 115, Train: 0.9830, Test: 0.9000\n",
      "Epoch: 116, Train: 0.9830, Test: 0.8960\n",
      "Epoch: 117, Train: 0.9819, Test: 0.8940\n",
      "Epoch: 118, Train: 0.9801, Test: 0.8960\n",
      "Epoch: 119, Train: 0.9789, Test: 0.8960\n",
      "Epoch: 120, Train: 0.9801, Test: 0.8980\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    F.nll_loss(model()[data.train_mask], data.y[data.train_mask]).backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "    log_probs, accs = model(), []\n",
    "    for _, mask in data('train_mask', 'test_mask'):\n",
    "        pred = log_probs[mask].max(1)[1]\n",
    "        acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n",
    "        accs.append(acc)\n",
    "    return accs\n",
    "\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    train()\n",
    "    train_acc, test_acc = test()\n",
    "    print(f'Epoch: {epoch:03d}, Train: {train_acc:.4f}, Test: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d30738",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da4c2ebb",
   "metadata": {},
   "source": [
    "Epoch: 059, Train: 0.9848, Test: 0.9020\n",
    "Epoch: 104, Train: 0.9830, Test: 0.9100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c303d796",
   "metadata": {},
   "source": [
    "## Manual Measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b407e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "241d50eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics as stat\n",
    "\n",
    "sparsity=0.0\n",
    "Eva_final=dict()\n",
    "\n",
    "\n",
    "Base_model_accuracy=[]\n",
    "T_base_model=[]\n",
    "Num_parm_base_model=[]\n",
    "Base_model_size=[]\n",
    "\n",
    "Pruned_model_accuracy=[]\n",
    "T_pruned_model=[]\n",
    "Num_parm_pruned_model=[]\n",
    "Pruned_model_size=[]\n",
    "\n",
    "Pruned_finetune_model_accuracy=[]\n",
    "T_pruned_finetune_model=[]\n",
    "Num_parm_pruned_finetune_model=[]\n",
    "Pruned_finetune_model_size=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f78c025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.015624761581420898,\n",
       " 0.015621662139892578,\n",
       " 0.01562047004699707,\n",
       " 0.015625953674316406,\n",
       " 0.015632152557373047,\n",
       " 0.015627384185791016,\n",
       " 0.015624284744262695,\n",
       " 0.015650033950805664,\n",
       " 0.01562786102294922,\n",
       " 0.015625]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_pruned_finetune_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c5b039f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All measurement about pruning process of sparsity:0.0% \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'base model accuracy': 0.9488,\n",
       " 'time inference of base model': 0.013151,\n",
       " 'number parmameters of base model': 23063,\n",
       " 'base_model_size': 738016,\n",
       " 'pruned model accuracy': 0.9488,\n",
       " 'time inference of pruned model': 0.014715,\n",
       " 'number parmameters of pruned model': 23063,\n",
       " 'pruned model size': 738016,\n",
       " 'pruned finetune model accuracy': 0.9668,\n",
       " 'time inference of pruned finetune model': 0.015628,\n",
       " 'number parmameters of pruned finetune model': 23063,\n",
       " 'pruned finetune model size': 738016}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Eva_final=dict()\n",
    "base_model_accuracy_mean = stat.mean(Base_model_accuracy)\n",
    "base_model_accuracy_std =  stat.stdev(Base_model_accuracy)\n",
    "#desc = \"{:.3f} ± {:.3f}\".format(acc_mean,acc_std)\n",
    "\n",
    "Eva_final.update({'base model accuracy':float(format(base_model_accuracy_mean, '.4f'))})\n",
    "                 \n",
    "t_base_model_mean =stat.mean(T_base_model)\n",
    "#t_base_model_std =t_base_model.std()\n",
    "#desc = \"{:.3f} ± {:.3f}\".format(acc_mean,acc_std)\n",
    "Eva_final.update({'time inference of base model':float(format(t_base_model_mean, '.6f'))})\n",
    "\n",
    "num_parm_base_model_mean = stat.mean(Num_parm_base_model)\n",
    "#num_parm_base_model_std = num_parm_base_model.std()\n",
    "#desc = \"{:.3f} ± {:.3f}\".format(acc_mean,acc_std)\n",
    "Eva_final.update({'number parmameters of base model':num_parm_base_model_mean})\n",
    "\n",
    "base_model_size_mean = stat.mean(Base_model_size)\n",
    "#base_model_size_std = base_model_size.std()\n",
    "#desc = \"{:.3f} ± {:.3f}\".format(acc_mean,acc_std)\n",
    "Eva_final.update({'base_model_size':base_model_size_mean})\n",
    "\n",
    "#################################\n",
    "\n",
    "pruned_model_accuracy_mean =stat.mean(Pruned_model_accuracy)\n",
    "pruned_model_accuracy_std = stat.stdev(Pruned_model_accuracy)\n",
    "#desc = \"{:.3f} ± {:.3f}\".format(acc_mean,acc_std)\n",
    "Eva_final.update({'pruned model accuracy':float(format(pruned_model_accuracy_mean, '.4f'))})\n",
    "                 \n",
    "\n",
    "t_pruned_model_mean = stat.mean(T_pruned_model)\n",
    "#t_base_model_std =t_dence_model.std()\n",
    "#desc = \"{:.3f} ± {:.3f}\".format(acc_mean,acc_std)\n",
    "Eva_final.update({'time inference of pruned model':float(format(t_pruned_model_mean, '.6f'))})\n",
    "\n",
    "num_parm_pruned_model_mean = stat.mean(Num_parm_pruned_model)\n",
    "#num_parm_base_model_std = num_parm_base_model.std()\n",
    "#desc = \"{:.3f} ± {:.3f}\".format(acc_mean,acc_std)\n",
    "Eva_final.update({'number parmameters of pruned model':num_parm_pruned_model_mean})\n",
    "\n",
    "pruned_model_size_mean =stat.mean( Pruned_model_size)\n",
    "#base_model_size_std = base_model_size.std()\n",
    "#desc = \"{:.3f} ± {:.3f}\".format(acc_mean,acc_std)\n",
    "Eva_final.update({'pruned model size':pruned_model_size_mean})\n",
    "\n",
    "#################################\n",
    "pruned_finetune_model_accuracy_mean =stat.mean(Pruned_finetune_model_accuracy)\n",
    "pruned_finetune_model_accuracy_std = stat.stdev(Pruned_finetune_model_accuracy)\n",
    "#desc = \"{:.3f} ± {:.3f}\".format(acc_mean,acc_std)\n",
    "Eva_final.update({'pruned finetune model accuracy':float(format(pruned_finetune_model_accuracy_mean, '.4f'))})\n",
    "                 \n",
    "\n",
    "t_pruned_finetune_model_mean =stat.mean(T_pruned_finetune_model)\n",
    "#t_base_model_std =t_dence_model.std()\n",
    "#desc = \"{:.3f} ± {:.3f}\".format(acc_mean,acc_std)\n",
    "Eva_final.update({'time inference of pruned finetune model':float(format(t_pruned_finetune_model_mean,'.6f'))})\n",
    "\n",
    "num_parm_pruned_finetune_model_mean =stat.mean(Num_parm_pruned_finetune_model)\n",
    "#num_parm_base_model_std = num_parm_base_model.std()\n",
    "#desc = \"{:.3f} ± {:.3f}\".format(acc_mean,acc_std)\n",
    "Eva_final.update({'number parmameters of pruned finetune model':num_parm_pruned_finetune_model_mean})\n",
    "\n",
    "pruned_finetune_model_size_mean = stat.mean(Pruned_finetune_model_size)\n",
    "#base_model_size_std = base_model_size.std()\n",
    "#desc = \"{:.3f} ± {:.3f}\".format(acc_mean,acc_std)\n",
    "Eva_final.update({'pruned finetune model size':pruned_finetune_model_size_mean})\n",
    "\n",
    "\n",
    "#################################\n",
    "\n",
    "\n",
    "print(f\"All measurement about pruning process of sparsity:{sparsity*100}% \")   \n",
    "Eva_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ae2a600",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cora_Node_00={'base model accuracy': 0.9488,\n",
    " 'time inference of base model': 0.013151,\n",
    " 'number parmameters of base model': 23063,\n",
    " 'base_model_size': 738016,\n",
    " 'pruned model accuracy': 0.9488,\n",
    " 'time inference of pruned model': 0.014715,\n",
    " 'number parmameters of pruned model': 23063,\n",
    " 'pruned model size': 738016,\n",
    " 'pruned finetune model accuracy': 0.9668,\n",
    " 'time inference of pruned finetune model': 0.015628,\n",
    " 'number parmameters of pruned finetune model': 23063,\n",
    " 'pruned finetune model size': 738016}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2176b444",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
